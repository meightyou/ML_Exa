# ------------ MACHINE LEARNING CODE ------------------

```{r, echo = FALSE, message = FALSE, warning = FALSE}
source(here::here("scripts/setup.R"))
```

# Data Loading

```{r, echo = FALSE, message = FALSE}
DocVis <- read_csv("DocVis.csv")

german <- read_csv("german.csv")

nursing_data <- read_csv("nursing_data.csv")

real_estate <- read_csv("real_estate_data.csv")

Wine <- read_csv("Wine.csv")

imports.85 <- read.csv("imports-85.data", 
                       header=FALSE, na.strings="?")

```

# Course 0

## EDA

### Data Rename

```{r, echo = FALSE, message = FALSE}
names(imports.85) <- c("symboling", "normalized_losses", "make", "fuel_type", "aspiration",
                       "num_doors", "body_style", "drive_wheels", "engine_location", "wheel_base",
                       "length", "width", "height","curb_weight", "engine_type", "num_cylinders",
                       "engine_size", "fuel_system", "bore", "stroke", "compression_ratio", "horsepower",
                       "peak_rpm", "city_mpg", "highway_mpg", "price")
```

### Data structure and summary

```{r, echo = FALSE, message = FALSE}

str(imports.85)
head(imports.85)
summary(imports.85)

# Turning character columns into factors through a loop
for (i in 1:ncol(imports.85)){
  if (class(imports.85[,i])=="character"){
    imports.85[,i] <- factor(imports.85[,i])
  }
}
# same operation can also be done through the `lapply` function
# imports.85[sapply(imports.85, is.character)] <-
#   lapply(imports.85[sapply(imports.85, is.character)],
#          as.factor)

str(imports.85)
summary(imports.85)

dfSummary(imports.85, style="grid")

view(dfSummary(imports.85, style="grid",plain.ascii = FALSE, tmp.img.dir = "/tmp"))

## first look at the current levels
levels(imports.85$fuel_system)
## Now rename the levels merging 4bbl[3], mfi[5], spfi[8] to "other"
levels(imports.85$fuel_system)[c(3,5,8)] <- "other"

## see the result
summary(imports.85)

```

### Graph for each variable

```{r, echo = FALSE, message = FALSE}


## Individually
p1 <- ggplot(imports.85, aes(x="price", y=price)) + 
  geom_boxplot()+xlab("")
p1
p2 <- ggplot(imports.85, aes(x="price", y=price)) + 
  geom_violin()+xlab("")
p2
p3 <- ggplot(imports.85, aes(x=price)) + 
  geom_histogram(color="black", fill="white")
p3
## The 3 plots on the same page
grid.arrange(p1, p2, p3, nrow=2, layout_matrix=matrix(c(1,2,3,3), byrow=TRUE, nc=2))

## pie chart with the basic plot function
## (ggplot2 is not good at producing pie charts)
pie(table(imports.85$fuel_system))

## bar plots
imports.85 %>% count(fuel_system) %>%
  ggplot(aes(y=n, x=fuel_system)) + 
  geom_bar(stat="identity")+coord_flip()

imports.85 %>% count(fuel_system) %>%
  ggplot(aes(fill=fuel_system, y=n, x="Fuel System")) + 
  geom_bar(position="stack", stat="identity", color="black")+xlab("")


## pie chart with the basic plot function
## (ggplot2 is not good at producing pie charts)
pie(table(imports.85$fuel_system))

## bar plots
imports.85 %>% count(fuel_system) %>%
  ggplot(aes(y=n, x=fuel_system)) + 
  geom_bar(stat="identity")+coord_flip()

imports.85 %>% count(fuel_system) %>%
  ggplot(aes(fill=fuel_system, y=n, x="Fuel System")) + 
  geom_bar(position="stack", stat="identity", color="black")+xlab("")
```

### Several graphs

```{r, echo = FALSE, message = FALSE}

## For the numerical variables
imports.85 %>%
  keep(is.numeric) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_histogram()

## For the categorical variables
imports.85 %>%
  keep(is.factor) %>% 
  gather() %>% 
  ggplot(aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_bar(stat="count")+coord_flip()

imports.85 %>%
  keep(is.numeric) %>% 
  gather()
```

### Scatterplot matrix for several variables

```{r, echo = FALSE, message = FALSE}
library(GGally)

imports.85 %>% select(length, height, width, price) %>% 
 ggpairs()

imports.85 %>% select(length, height, width, price, fuel_system) %>% 
  ggpairs(columns=1:4, aes(colour=fuel_system))

imports.85 %>% select(fuel_system, fuel_type, aspiration) %>% 
  ggpairs()

imports.85 %>% select(body_style, num_doors, width, price) %>% 
  ggpairs()

```

## Recoding and feature engineering

### Building a new feature

```{r, echo = FALSE, message = FALSE}

imports.85 %>% mutate(volume=height*width*length) %>% 
  select(price, height, width, length, volume) %>% ggpairs
```

### Recoding a variable

```{r, echo = FALSE, message = FALSE}

imports.85 %>% mutate(num_cyl_num=case_when(
  num_cylinders=="two"~2, 
  num_cylinders=="three"~3, 
  num_cylinders=="four"~4, 
  num_cylinders=="five"~5, 
  num_cylinders=="six"~6, 
  num_cylinders=="eight"~8, 
  num_cylinders=="twelve"~12)) %>% 
  select(price, num_cyl_num, num_cylinders) %>% ggpairs

library(fastDummies)
imports.85 %>% select(fuel_system) %>% dummy_cols(remove_first_dummy = TRUE)

```



# COURSE 1 : K-Nearest Neighbours

## 1 K-NN: a gentle introduction

```{r, echo = FALSE, message = FALSE}
library(dplyr)
library(caret)
iris
iris <- iris

mod.knn <- knn3(data = iris, Species~., k = 2) ## build the knn model
predict(mod.knn, newdata = iris, type = "class")

set.seed(123) ## for replication purpose

index.tr <- sample(1:nrow(iris), replace=FALSE, size=0.75*nrow(iris))
index.tr ## the index of the rows of iris that will be in the training set

iris.tr <- iris[index.tr,] ## the training set
iris.te <- iris[-index.tr,] ## the test set, the minus sign is telling take ALL BUT the training set

mod.knn <- knn3(data=iris.tr, Species~., k=2)
iris.te.pred <- predict(mod.knn, newdata = iris.te, type="class")

table(Pred=iris.te.pred, Observed=iris.te[,5])

mod.knn <- knn3(data=iris.tr, Species~., k=3)
iris.te.pred <- predict(mod.knn, newdata = iris.te, type="class")

table(Pred=iris.te.pred, Observed=iris.te[,5])

class(mod.knn) # class = knn

```

## 2 K-NN REGRESSION

```{r, echo = FALSE, message = FALSE}
imports.85 <- read.csv("imports-85.data", 
                       header=FALSE, na.strings="?")# replaces the ? with NA

names(imports.85) <- c("symboling", "normalized_losses", "make", "fuel_type", "aspiration",
                       "num_doors", "body_style", "drive_wheels", "engine_location", "wheel_base",
                       "length", "width", "height","curb_weight", "engine_type", "num_cylinders",
                       "engine_size", "fuel_system", "bore", "stroke", "compression_ratio", "horsepower",
                       "peak_rpm", "city_mpg", "highway_mpg", "price")#renaming the columns because not specified in the doc




tmp <- imports.85 %>% select(where(is.numeric))#only select columns with numerical data
tmp <- filter(tmp, complete.cases(tmp))#and then only select rows where there is no NAs

tmp# tmp means temporary

set.seed(123)
index.tr <- sample(1:nrow(tmp), size=0.75*nrow(tmp), replace = FALSE)
tmp.tr <- tmp[index.tr,]
tmp.te <- tmp[-index.tr,]
mod.knn <- knnreg(data=tmp.tr, price~., k=3)# 3 nearest neighbours
tmp.pred <- predict(mod.knn, newdata=tmp.te)

tmp.tr#just to view
tmp.te#just to view

tmp.te %>% mutate(pred=tmp.pred) %>%
  ggplot(aes(x=price, y=pred)) + 
  geom_point() + geom_abline(slope=1, intercept = 0)

```

## 3 K-NN: mixture of feature types

```{r, echo = FALSE, message = FALSE}

## tmp is imports.85 without incomplete cases and without price
imp.comp <- imports.85 %>% filter(complete.cases(imports.85))#select only rows with no missing data
y <- imp.comp$price#y variable
imp.comp <- imp.comp %>% select(!price)#x variable = all but y variable

## The numerical variables in tmp are standardized
imp.num <- imp.comp %>% select(where(is.numeric)) %>% scale() %>% as.data.frame()

## the dummy variables of the numerical features of tmp are created
library(fastDummies)
imp.dumm <- imp.comp %>% select(!where(is.numeric)) %>% 
  dummy_cols(remove_first_dummy = FALSE, remove_selected_columns = TRUE)

## These dummy variables are added to tmp
imp.dat <- data.frame(imp.num, imp.dumm)

## The names of the two problematic brands are changed
names(imp.dat)[c(16,25)] <- c("make_alfa_romeo","make_mercredes_benz")

## The raw price is added to tmp
imp.dat$price <- y

set.seed(123)
index.tr <- sample(1:nrow(imp.dat), size=0.75*nrow(imp.dat), replace = FALSE)
imp.tr <- imp.dat[index.tr,]
imp.te <- imp.dat[-index.tr,]
mod.knn <- knnreg(data=imp.tr, price~., k=3)
imp.pred <- predict(mod.knn, newdata=imp.te)
imp.te %>% mutate(pred=imp.pred) %>%
  ggplot(aes(x=price, y=pred)) + 
  geom_point() + geom_abline(slope=1, intercept = 0)

```

# Course 2 Models: Naive Bayes

## 1 Conditional density plots

```{r, echo = FALSE, message = FALSE}

library(naivebayes)
iris.nb <- naive_bayes(Species ~ .,
                       data = iris, usekernel=TRUE)
par(mfrow=c(2,2))
plot(iris.nb, arg.num = list(col = 1:3,
                             legend.position = "topright",
                             legend.cex = 0.8),
     prob="conditional")
par(mfrow=c(1,1))

iris.nb

iris.nb <- naive_bayes(Species ~ .,
                       data = iris, usekernel=FALSE) 
par(mfrow=c(2,2))
plot(iris.nb, arg.num = list(col = 1:3,
                             legend.position = "topright",
                             legend.cex = 0.8), prob="conditional")
par(mfrow=c(1,1))

iris.nb

```

## 2 Predictions

```{r, echo = FALSE, message = FALSE}

predict(iris.nb, newdata = iris[,-5])
predict(iris.nb, newdata = iris[,-5], type="prob")

```

## 3 Priors

```{r, echo = FALSE, message = FALSE}

iris.nb <- naive_bayes(Species ~ .,
                       data = iris, usekernel=FALSE, prior = c(0.1,0.9,0.1)) 
par(mfrow=c(2,2))
plot(iris.nb, arg.num = list(col = 1:3,
                             legend.position = "topright",
                             legend.cex = 0.8), prob="conditional")
par(mfrow=c(1,1))

predict(iris.nb, newdata = iris[,-5])

```

## 4 Categorical features

```{r, echo = FALSE, message = FALSE}

DocVis <- read.csv("DocVis.csv") # adapt the path to the file; use the Import Dataset tool
DocVis.nb <- naive_bayes(visits~., data=DocVis, usekernel = TRUE)
plot(DocVis.nb, prob = "conditional")

table(pred=predict(DocVis.nb), obs=DocVis$visits)

```


# Course 3 

```{r, echo = FALSE, message = FALSE}


```

# Course 4 

## 1 Classification tree

### 1.1 Prepare the data
```{r, echo = FALSE, message = FALSE}
library(ISLR)
library(dplyr)
MyCarseats <- Carseats %>% mutate(SaleHigh=ifelse(Sales > 7.5, "Yes", "No"))
MyCarseats <- MyCarseats %>% select(-Sales)

set.seed(123) # for reproducibility 
index.tr <- sample(x=1:nrow(MyCarseats), size=2/3*nrow(MyCarseats), replace=FALSE)
df.tr <- MyCarseats[index.tr,]
df.te <- MyCarseats[-index.tr,]

```

### 1.2 Classification tree fit and plot

```{r, echo = FALSE, message = FALSE}
library(rpart)
library(rpart.plot)
set.seed(1234)
carseats.tree <- rpart(SaleHigh ~ ., data=df.tr)
rpart.plot(carseats.tree)

```

### 1.3 Pruning the tree

```{r, echo = FALSE, message = FALSE}
plotcp(carseats.tree)
carseats.tree.prune <- prune(carseats.tree, cp=0.025)
rpart.plot(carseats.tree.prune)
library(adabag)
set.seed(123455)
rpart.plot(autoprune(SaleHigh ~ ., data=df.tr))

```

### 1.4 Predictions

```{r, echo = FALSE, message = FALSE}
#answer 
MyCarseats[1,]

pred <- predict(carseats.tree.prune, newdata=df.te, type="class")
table(Pred=pred, Obs=df.te$SaleHigh)

predict(carseats.tree.prune, newdata=df.te, type="prob")

```

## 2 Regression tree

```{r, echo = FALSE, message = FALSE}


set.seed(123)
carseats.reg <- rpart(Sales ~ ., data=Carseats)
rpart.plot(carseats.reg)

carseat.reg.pred <- predict(carseats.reg)
plot(carseat.reg.pred ~ Carseats$Sales,
     xlab="Sales", ylab="Predictions")
abline(0,1, col="red")

```


# Course 5 

```{r, echo = FALSE, message = FALSE}


```

# Course 6 

```{r, echo = FALSE, message = FALSE}


```

# Course 7 

```{r, echo = FALSE, message = FALSE}


```

# Course 8 

```{r, echo = FALSE, message = FALSE}


```

# Course 9 

```{r, echo = FALSE, message = FALSE}


```


